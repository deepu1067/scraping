{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "from urllib.parse import quote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('../key.json', 'r')\n",
    "API_KEY = json.load(file)[0]['OMDB_API']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# movie_dict = pd.read_csv(\"movies.csv\").drop(\"Unnamed: 0\", axis=1)\n",
    "# movie_dict.to_csv(\"movies.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_dict = pd.read_csv(\"movies.csv\").to_dict(orient=\"records\")\n",
    "movies = [i['title'].lower().replace(\"º\", \"°\").replace(\"’\", \"'\") for i in movie_dict] #movie list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrapped = pd.read_csv(\"new_merged_scrapped.csv\")\n",
    "scrapped = scrapped.drop_duplicates(subset='Title', keep='first')\n",
    "scrapped_dict = scrapped.to_dict(orient=\"records\")\n",
    "scrapped_movies = [i['Title'].lower() for i in scrapped_dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Alexander and the Terrible, Horrible, No Good, …\".replace(\" …\", \"\")\n",
    "# \"Alexander and the Terrible, Horrible, No Good, Very Bad Day\".find(\"Alexander and the Terrible, Horrible, No Good,\")\n",
    "\n",
    "# l = [\"done\", \"Alexander and the Terrible, Horrible, No Good, Very Bad Day\"]\n",
    "# l[1].endswith(\" …\")\n",
    "# scrapped = scrapped.drop(\"Unnamed: 0.1\", axis=1)\n",
    "# scrapped = scrapped.drop(\"Unnamed: 0\", axis=1)\n",
    "\n",
    "# scrapped = scrapped.drop(272)\n",
    "# scrapped = scrapped.drop(743)\n",
    "# scrapped = scrapped.drop(776)\n",
    "# scrapped.to_csv(\"movie_info.csv\", index=False)\n",
    "\n",
    "\n",
    "# \"no se aceptan devoluciones 2: el regreso de loreto peralta\".find(\"no se aceptan devoluciones\")\n",
    "# len(scrapped)\n",
    "scrapped.to_csv('movie_info.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, i in enumerate(movies):\n",
    "    if i.endswith(\"…\"):\n",
    "        movies[index] = i.replace(\"…\", \"\").strip()\n",
    "        # print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = list(set(movies))\n",
    "scrapped_movies = list(set(scrapped_movies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "leftover = []\n",
    "for movie in movies:\n",
    "    if movie not in scrapped_movies:\n",
    "        leftover.append(movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'movies': movies})\n",
    "df2 = pd.DataFrame({'leftover': leftover})\n",
    "df3 = pd.DataFrame({'scrapped':scrapped_movies})\n",
    "\n",
    "result_df = pd.merge(df1, df2, left_on='movies', right_on='leftover', how='outer')\n",
    "\n",
    "result_df = pd.merge(result_df, df3, left_on='movies', right_on='scrapped', how='outer')\n",
    "\n",
    "result_df.to_csv(\"output.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2005, 1873, 132, 2005)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(movies), len(scrapped_movies), len(leftover) , (len(scrapped_movies)+len(leftover))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_list = []\n",
    "count = 0\n",
    "not_added = 0\n",
    "\n",
    "for m in leftover:\n",
    "    formatted = quote(m)\n",
    "    url = f\"http://www.omdbapi.com/?t={formatted}&apikey=2c60d316\"\n",
    "    response = requests.get(url)\n",
    "    # print(url)\n",
    "    if response.status_code == 200:\n",
    "        data = json.loads(response.text)\n",
    "        if data['Response'] != 'False':\n",
    "            new_list.append(data)\n",
    "            print(data['Title'], m)\n",
    "            count += 1\n",
    "        else:\n",
    "            not_added += 1\n",
    "    else:\n",
    "        print(f\"Status code: {response.status_code}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 132)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count , not_added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " 1935,\n",
       " RangeIndex(start=0, stop=0, step=1),\n",
       " Index(['Title', 'Year', 'Rated', 'Released', 'Runtime', 'Genre', 'Director',\n",
       "        'Writer', 'Actors', 'Plot', 'Language', 'Country', 'Awards', 'Poster',\n",
       "        'Ratings', 'Metascore', 'imdbRating', 'imdbVotes', 'imdbID', 'Type',\n",
       "        'DVD', 'BoxOffice', 'Production', 'Website', 'totalSeasons',\n",
       "        'Response'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_scrapped = pd.DataFrame(new_list)\n",
    "len(new_scrapped), len(scrapped), new_scrapped.columns, scrapped.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_new = pd.concat([scrapped, new_scrapped], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_new.to_csv('new_merged_scrapped.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dms = pd.read_csv(\"new_merged_scrapped.csv\")\n",
    "# dms = dms.drop_duplicates()\n",
    "\n",
    "# dms = dms.drop(791)\n",
    "# dms.to_csv(\"new_merged_scrapped.csv\", index=False)\n",
    "# # dms = dms.drop(752)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1935"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scrapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 1928)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
